wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: yashjain14 (yashjain14-nanyang-technological-university-singapore) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
[rank0]: Traceback (most recent call last):
[rank0]:   File "/home/UG/yash012/.conda/envs/llm_env/lib/python3.12/site-packages/huggingface_hub/utils/_http.py", line 409, in hf_raise_for_status
[rank0]:     response.raise_for_status()
[rank0]:   File "/home/UG/yash012/.conda/envs/llm_env/lib/python3.12/site-packages/requests/models.py", line 1024, in raise_for_status
[rank0]:     raise HTTPError(http_error_msg, response=self)
[rank0]: requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/google/gemma-2b/resolve/main/config.json

[rank0]: The above exception was the direct cause of the following exception:

[rank0]: Traceback (most recent call last):
[rank0]:   File "/home/UG/yash012/.conda/envs/llm_env/lib/python3.12/site-packages/transformers/utils/hub.py", line 424, in cached_files
[rank0]:     hf_hub_download(
[rank0]:   File "/home/UG/yash012/.conda/envs/llm_env/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
[rank0]:     return fn(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/UG/yash012/.conda/envs/llm_env/lib/python3.12/site-packages/huggingface_hub/file_download.py", line 961, in hf_hub_download
[rank0]:     return _hf_hub_download_to_cache_dir(
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/UG/yash012/.conda/envs/llm_env/lib/python3.12/site-packages/huggingface_hub/file_download.py", line 1068, in _hf_hub_download_to_cache_dir
[rank0]:     _raise_on_head_call_error(head_call_error, force_download, local_files_only)
[rank0]:   File "/home/UG/yash012/.conda/envs/llm_env/lib/python3.12/site-packages/huggingface_hub/file_download.py", line 1596, in _raise_on_head_call_error
[rank0]:     raise head_call_error
[rank0]:   File "/home/UG/yash012/.conda/envs/llm_env/lib/python3.12/site-packages/huggingface_hub/file_download.py", line 1484, in _get_metadata_or_catch_error
[rank0]:     metadata = get_hf_file_metadata(
[rank0]:                ^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/UG/yash012/.conda/envs/llm_env/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
[rank0]:     return fn(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/UG/yash012/.conda/envs/llm_env/lib/python3.12/site-packages/huggingface_hub/file_download.py", line 1401, in get_hf_file_metadata
[rank0]:     r = _request_wrapper(
[rank0]:         ^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/UG/yash012/.conda/envs/llm_env/lib/python3.12/site-packages/huggingface_hub/file_download.py", line 285, in _request_wrapper
[rank0]:     response = _request_wrapper(
[rank0]:                ^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/UG/yash012/.conda/envs/llm_env/lib/python3.12/site-packages/huggingface_hub/file_download.py", line 309, in _request_wrapper
[rank0]:     hf_raise_for_status(response)
[rank0]:   File "/home/UG/yash012/.conda/envs/llm_env/lib/python3.12/site-packages/huggingface_hub/utils/_http.py", line 426, in hf_raise_for_status
[rank0]:     raise _format(GatedRepoError, message, response) from e
[rank0]: huggingface_hub.errors.GatedRepoError: 401 Client Error. (Request ID: Root=1-67f36ded-171fadf14a42f5482eb6eef4;631b42cd-d580-4882-bb2d-63fb43760f84)

[rank0]: Cannot access gated repo for url https://huggingface.co/google/gemma-2b/resolve/main/config.json.
[rank0]: Access to model google/gemma-2b is restricted. You must have access to it and be authenticated to access it. Please log in.

[rank0]: The above exception was the direct cause of the following exception:

[rank0]: Traceback (most recent call last):
[rank0]:   File "/home/UG/yash012/Gemma_TSA/pipeline/compare_transformers.py", line 141, in <module>
[rank0]:     main()
[rank0]:   File "/home/UG/yash012/Gemma_TSA/pipeline/compare_transformers.py", line 66, in main
[rank0]:     model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)
[rank0]:             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/UG/yash012/.conda/envs/llm_env/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py", line 531, in from_pretrained
[rank0]:     config, kwargs = AutoConfig.from_pretrained(
[rank0]:                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/UG/yash012/.conda/envs/llm_env/lib/python3.12/site-packages/transformers/models/auto/configuration_auto.py", line 1112, in from_pretrained
[rank0]:     config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
[rank0]:                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/UG/yash012/.conda/envs/llm_env/lib/python3.12/site-packages/transformers/configuration_utils.py", line 590, in get_config_dict
[rank0]:     config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)
[rank0]:                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/UG/yash012/.conda/envs/llm_env/lib/python3.12/site-packages/transformers/configuration_utils.py", line 649, in _get_config_dict
[rank0]:     resolved_config_file = cached_file(
[rank0]:                            ^^^^^^^^^^^^
[rank0]:   File "/home/UG/yash012/.conda/envs/llm_env/lib/python3.12/site-packages/transformers/utils/hub.py", line 266, in cached_file
[rank0]:     file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/UG/yash012/.conda/envs/llm_env/lib/python3.12/site-packages/transformers/utils/hub.py", line 481, in cached_files
[rank0]:     raise OSError(
[rank0]: OSError: You are trying to access a gated repo.
[rank0]: Make sure to have access to it at https://huggingface.co/google/gemma-2b.
[rank0]: 401 Client Error. (Request ID: Root=1-67f36ded-171fadf14a42f5482eb6eef4;631b42cd-d580-4882-bb2d-63fb43760f84)

[rank0]: Cannot access gated repo for url https://huggingface.co/google/gemma-2b/resolve/main/config.json.
[rank0]: Access to model google/gemma-2b is restricted. You must have access to it and be authenticated to access it. Please log in.
[rank0]:[W407 14:17:18.309267725 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
